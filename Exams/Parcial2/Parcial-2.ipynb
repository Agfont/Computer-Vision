{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ----------------------------------------------------------------------------------------------------\n",
    "----------------------------------------------------------------------------------------------------\n",
    "<h1><center>\n",
    "    \n",
    "Practical exam on Computer Vision\n",
    "    \n",
    "Second Part\n",
    " \n",
    "( January, 20th, 2022 )\n",
    "</center></h1>    \n",
    "\n",
    "----------------------------------------------------------------------------------------------------\n",
    "----------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the practical exam that should be developed during 2 hours. Note that to approve the exam, both parts (theoretical and practical ones) should be approved. Each exercise is defined with the corresponding score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where is Wally?\n",
    "\n",
    "'Where's Wally' is a popular British series of puzzle books that has garnered interest in both children and adults. Finding Waldo (as is named in North America) is never easy but we are going to make it quickly using image processing techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ex. 1.1** (0.5 points) Load the image `finding_waldo.jpg` together with the template `template.jpg` from the folder `images_exam`. Obtain the image template2 dividing by 2 the intensity of template. Show the three images in one single figure using the `subplots` function and print their principal image features: type and shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage.io import imread, imsave\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.feature import match_template\n",
    "\n",
    "#your solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ex. 1.2** (1.5 points) Show the euclidean distance and the normalized cross-correlation between the original image and both templates. Print the maximum and the minimum of the two distances for each of the templates. Explain what is the difference when using euclidean distance and the normalized cross-correlation for template matching.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your solution\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ex 1.3** (1 point) Localize Waldo in the image using both templates separately and show the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your solution\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a pleasure see you here once again! The Squid Game has not finished for you!\n",
    "\n",
    "We are going to play the Green Ligth, Red Ligth game, once again. Last time we asked you to anonymize the images in order to confuse the gigant doll, to save people. Now we need to be more specific and we are going to localize the people firstly.\n",
    "\n",
    "<img src=\"images_exam/doll.jpg\" width=\"400\" height=\"40\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ex.2.1** (0.5 point) Load the image collection from  `images_exam\\green_light\\` and visualize the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ex.2.2** (0.5 point) We are going to use a cascade face detector.\n",
    "\n",
    "From 'skimage' import `data` to load the coresponding face detector and the trained file `data.lbp_frontal_face_cascade_filename()`. Try it on the first image and visualize the result (as shown) in the first image of the collection.\n",
    "\n",
    "<img src=\"images_exam/FaceDetector.png\" width=\"400\" height=\"40\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ex. 2.3** (1 points) Use a gaussian to anonimize only the faces. Notice that we are not asking about blurring the whole image but only those areas that are marked as faces by the algorithm. Apply it on the first image of the image collection. Comment your solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ex. 2.4** (1 points) Now, update the function `frame_update` to anonimize the faces in the video. Explain your solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib nbagg\n",
    "from skimage.feature import Cascade\n",
    "from skimage import data\n",
    "from matplotlib import patches\n",
    "from skimage import filters\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#your solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to test the image classification using a PCA model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ex 3.1** (1 points) From `./images_exam/AnimalFace/`, load those images corresponding to bear (i.e `./images_exam/AnimalFace/BearHead`), deer (folder `DeerHead`), monkey (`MonkeyHead`), eagle (`EagleHead`) and panda (`PandaHead`). \n",
    "\n",
    "Save all the images in one single data array and make the corresponding labeling array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from skimage.transform import resize\n",
    "import os\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.io import imread\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your solution\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ex 3.2** (1 points) Prepare the images as a list of vectors with length equal to the image pixels and divide the dataset into train and test sets (0.7/0.3, respectively)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.3** (1 points) Train a PCA model, chossing a number of components that preserve 96% of information (i.e 0.96 of accumulated variance). Plot the accumulated variance to check the number of components.\n",
    "Hint: To this purpose you can check using 150, 160, 170, 180, 190 and 200 eigenvectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report \n",
    "\n",
    "#your solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.4** Train an AdaBoost Classification model in the original space and with the derived PCA data and 100 weak classifiers and compare the results (the performance of both recognition methods)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "#your solution\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
